# Diabetes-Data-Analysis

The objective of this project is to determine a person's likelihood of having diabetes. Machine learning techniques are applied to the Pima Indian Diabetes dataset, and 93% prediction accuracy is achieved. This project involved data preparation, outlier treatment, feature engineering, data visualisation, scaling, several supervised machine learning algorithms, performance analysis, etc.



Content:
1-  Importing Pima Indians Diabetes Database

2-  Exploratory Data Analysis

3-  Data Preprocessing

4-  Outlier Observation Analysis

5-  Visualization of dataset

6-  Feature Engineering

7-  Machine learning for prediction

8-  Logistic Regression

9-  Model Performance Analysis

10- Random Forest

11- K Nearest Neighbor

12- Support Vector Classifier

13- Decision Tree Classifier

14- Feature Importance in Decision Trees

15- Plotting Accuracy Scores of all ML Algorithms

16- Summary



In order to predict whether a person is likely to be a diabetic person or not, machine learning algorithms were applied to the PIMA Indian Diabetes Dataset.

The exploratory data analysis let us know the overview of our dataset, how many attributes it has, data types of attributes, and some statistics about attributes. Outcome variable also examined here.

Data preprocessing or data cleaning helps in refining the dataset. It makes our dataset well-formed and prepares data for analysis. Zero, duplicate, and null values are checked and replaced with respactive attribute median value.

Outliers are data points that are significantly different from the rest of the dataset. Outlier Observation Analysis tries to find these outliers and remove them.

Visualization of dataset helps in better understanding our dataset. Attribute value ranges are easily observed here. A heatmap of correlation indicates how strongly our attributes are related to the outcome variable. Pairplot and Histplot are also examined and incorporated in this project.

Feature engineering may improve the accuracy of machine learning models. New attributes (features) are created here. Label encoding and one hot encoding are required for converting our new attribute values into numerical values.

In order to perform machine learning algorithms, scaling and splitting the data is required. The Scikit-Learn library is used here for supervised machine learning. Logistic regression, random forest, K nearest neighbor, support vector classifier, and decision tree classifier methods are applied.

Model Performance Analysis involved a confusion matrix, ROC curve, accuracy score, etc., and plotting the accuracy scores of all ML algorithms. Thus, it is found that K nearest neighbours (KNN) has the highest accuracy of 93.75.
